{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vsb_power_line_first_try.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcglarry/kg_power_line/blob/master/vsb_power_line_first_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tJ52YwlYQQ3F",
        "colab_type": "code",
        "outputId": "ddf8651e-71ef-4828-e0c0-20070c4d0ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"vsb_power_line_eda.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1AZHJmuSwKCP8IOrOg_J96XmoQXDH-O-w\n",
        "\"\"\"\n",
        "\n",
        "# Step 1\n",
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PdEJ_ELCQQ_0",
        "colab_type": "code",
        "outputId": "125a5bd9-e007-4beb-e349-d437b3bfe911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mBtxvN-8Qtbn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-kMa02TGQt8u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "src= 'drive/My Drive/kaggle/vsb_power_line/data/'\n",
        "src_train= 'drive/My Drive/kaggle/vsb_power_line/data/train_test_data/train/'\n",
        "\n",
        "src_valid= 'drive/My Drive/kaggle/vsb_power_line/data/train_test_data/validation/'\n",
        "\n",
        "src_test = 'drive/My Drive/kaggle/vsb_power_line/data/train_test_data/test_data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGXMjgXrQI_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "#==============================================================================\n",
        "# # # Module\n",
        "#==============================================================================\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import subprocess\n",
        "import os\n",
        "import pickle\n",
        "import sklearn \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.densenet import DenseNet121, DenseNet169,DenseNet201, preprocess_input\n",
        "#from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.mobilenetv2 import MobileNetV2\n",
        "from keras.applications.nasnet import NASNetMobile,NASNetLarge\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator,  img_to_array, load_img\n",
        "\n",
        "\n",
        "\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, merge, Lambda,UpSampling2D, concatenate, \\\n",
        "Reshape, Dropout,Cropping2D,Activation, BatchNormalization\n",
        "from keras.models import Model, load_model\n",
        "import pandas as pd\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras import regularizers\n",
        "#from dummyPy import OneHotEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "import gc\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a9adGm-sQI_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_read_path = src_train ##\n",
        "val_read_path = src_valid ##\n",
        "\n",
        "h_size,w_size= 144,288\n",
        "size, channel = (144,288), 3\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "\n",
        "batch = 64\n",
        "\n",
        "\n",
        "save_dir =  src\n",
        "save_file = 'vsb_power_line_DenseNet121_1st_'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iGtGc6iTQI_s",
        "colab_type": "code",
        "outputId": "0e31e4cc-9294-4f3a-d07f-c42b149dbee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#==============================================================================\n",
        "# # # Train - Generator\n",
        "#==============================================================================\n",
        "'''\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        zoom_range=[0.9, 1.1], \n",
        "        fill_mode = 'reflect')\n",
        "'''\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    shear_range=0.2,\n",
        "    width_shift_range=1.0,\n",
        "    height_shift_range=1.0,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode = 'nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=src_train,\n",
        "    target_size=(h_size,w_size),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory=src_valid,\n",
        "    target_size=(h_size,w_size),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6970 images belonging to 2 classes.\n",
            "Found 1742 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d78XAzBQcLZI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_weight = {0:1,1:17}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hDfda-f5QI_v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def build_model_2():\n",
        "    inputs = Input(shape=(h_size,w_size,3))\n",
        "    #inputs = Lambda(lambda x: x/275. - 1.0)(inputs)\n",
        "    # create the base pre-trained model\n",
        "    base_model =DenseNet121(weights='imagenet',input_tensor=inputs,  include_top=True)\n",
        "\n",
        "\n",
        "\n",
        "    x = base_model.layers[51].output\n",
        "    print ('shape is = ', x.get_shape())\n",
        "\n",
        "    x= GlobalAveragePooling2D()(x)\n",
        "    print ('shape is = ', x.get_shape())\n",
        "    \n",
        "\n",
        "    x= BatchNormalization()(x)\n",
        "    x= Activation('relu')(x)\n",
        "    x = Dense(64,activation = 'sigmoid')(x)\n",
        "    x= BatchNormalization()(x)\n",
        "    x= Activation('relu')(x)\n",
        "    \n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(32,activation = 'sigmoid')(x)\n",
        "\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    x = Dense(128,activation='relu')(x)\n",
        "    \n",
        "    x= BatchNormalization()(x)\n",
        "    x= Activation('relu')(x)\n",
        "\n",
        "    #x = Dropout(0.3)(x)\n",
        "    #x = Dense(32,activation='relu')(x)\n",
        "    \n",
        "    x = Dense(32,activation='linear', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    \n",
        "    \n",
        "    x= BatchNormalization()(x)\n",
        "    x= Activation('relu')(x)\n",
        "    '''\n",
        "    \n",
        "    x= BatchNormalization()(x)\n",
        "    x= Activation('relu')(x)\n",
        "    x = Dropout(0.2)(x)   #BN with dropout ?? try .\n",
        "    \n",
        "    output = Dense(1,activation = 'sigmoid')(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jIw9Kw_iQI_z",
        "colab_type": "code",
        "outputId": "6197389c-73dc-4caf-f8c5-3504fb73e368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2558
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#==============================================================================\n",
        "# # # Train - Fit - ResNet\n",
        "#==============================================================================\n",
        "\n",
        "model = build_model_2()\n",
        "\n",
        "#model = load_model(save_dir+'Stage_1_DenseNet121_binary_generator_1_acc.h5')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape is =  (?, 36, 72, 128)\n",
            "shape is =  (?, 128)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 144, 288, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 150, 294, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 72, 144, 64)  9408        zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 72, 144, 64)  256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 72, 144, 64)  0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 74, 146, 64)  0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 36, 72, 64)   0           zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 36, 72, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 36, 72, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 36, 72, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 36, 72, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 36, 72, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 36, 72, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 36, 72, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 36, 72, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 36, 72, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 36, 72, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 36, 72, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 36, 72, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 36, 72, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 36, 72, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 36, 72, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 36, 72, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 36, 72, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 36, 72, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 36, 72, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 36, 72, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 36, 72, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 36, 72, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 36, 72, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 36, 72, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 36, 72, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 36, 72, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 36, 72, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 36, 72, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 36, 72, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 36, 72, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 36, 72, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 36, 72, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 36, 72, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 36, 72, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 36, 72, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 36, 72, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 36, 72, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 36, 72, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 36, 72, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 36, 72, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 36, 72, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 36, 72, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 36, 72, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 36, 72, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 36, 72, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 128)          0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128)          512         global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128)          0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 64)           8256        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64)           256         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64)           0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64)           0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 32)           2080        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32)           128         dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32)           0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            33          dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 393,025\n",
            "Trainable params: 388,673\n",
            "Non-trainable params: 4,352\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B7en0AlaVB4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lcnd6ZJbQI_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lr_epoch(epochs):\n",
        "    learning_rate_ = 0.0102\n",
        "    decay= 0.01/100.\n",
        "    lr = learning_rate_ - epochs*decay\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8-EuMbeQI_7",
        "colab_type": "code",
        "outputId": "87b9ece2-9d88-4d97-b19a-f0625033cb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Step_Train = train_generator.n//train_generator.batch_size\n",
        "\n",
        "print (train_generator.n, train_generator.batch_size)\n",
        "Step_Valid = valid_generator.n\n",
        "\n",
        "#define callback\n",
        "\n",
        "\n",
        "#define callback\n",
        "model_save_loss = save_dir+save_file+'_loss_2.h5'\n",
        "model_save_acc = save_dir+save_file+'_acc_2.h5'\n",
        "checkpoint_loss = ModelCheckpoint(model_save_loss, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "checkpoint_acc = ModelCheckpoint(model_save_acc, monitor='val_acc',save_best_only=True, mode='auto')\n",
        "earlystop = EarlyStopping(monitor='val_loss',  patience=20,  mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=0.00001,verbose=1)\n",
        "#（best val accuarcy saved \n",
        "lr_scheduler= LearningRateScheduler(lr_epoch,verbose=1)\n",
        "#callback_list = [checkpoint_loss,checkpoint_acc, earlystop,lr_scheduler]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6970 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BMnScYCyVXAw",
        "colab_type": "code",
        "outputId": "caaf0ddf-4c12-4732-b063-b6c040c89ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2256
        }
      },
      "cell_type": "code",
      "source": [
        "callback_list_1 = [checkpoint_loss,checkpoint_acc, earlystop]\n",
        "\n",
        "\n",
        "# starts trauning \n",
        "his = model.fit_generator(generator=train_generator,\n",
        "                            steps_per_epoch=Step_Train,\n",
        "                            validation_data=valid_generator,\n",
        "                            validation_steps=Step_Valid,\n",
        "                            epochs=150, verbose = 1,\n",
        "                             callbacks= callback_list_1, \n",
        "                            class_weight=class_weight)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "108/108 [==============================] - 858s 8s/step - loss: 1.3529 - acc: 0.4012 - val_loss: 0.4960 - val_acc: 0.9399\n",
            "Epoch 2/150\n",
            "108/108 [==============================] - 840s 8s/step - loss: 1.2181 - acc: 0.6113 - val_loss: 0.5079 - val_acc: 0.9399\n",
            "Epoch 3/150\n",
            "108/108 [==============================] - 839s 8s/step - loss: 1.1424 - acc: 0.5943 - val_loss: 0.6404 - val_acc: 0.9376\n",
            "Epoch 4/150\n",
            "108/108 [==============================] - 834s 8s/step - loss: 1.1301 - acc: 0.6296 - val_loss: 0.7294 - val_acc: 0.0595\n",
            "Epoch 5/150\n",
            "108/108 [==============================] - 831s 8s/step - loss: 1.1196 - acc: 0.6644 - val_loss: 0.3888 - val_acc: 0.9389\n",
            "Epoch 6/150\n",
            "108/108 [==============================] - 841s 8s/step - loss: 1.1096 - acc: 0.6380 - val_loss: 2.0252 - val_acc: 0.0693\n",
            "Epoch 7/150\n",
            "108/108 [==============================] - 851s 8s/step - loss: 1.1241 - acc: 0.6607 - val_loss: 0.4292 - val_acc: 0.9399\n",
            "Epoch 8/150\n",
            "108/108 [==============================] - 856s 8s/step - loss: 1.0813 - acc: 0.6922 - val_loss: 0.4886 - val_acc: 0.9066\n",
            "Epoch 9/150\n",
            "108/108 [==============================] - 837s 8s/step - loss: 1.0420 - acc: 0.6768 - val_loss: 0.5635 - val_acc: 0.8221\n",
            "Epoch 10/150\n",
            "108/108 [==============================] - 833s 8s/step - loss: 1.0722 - acc: 0.6608 - val_loss: 0.6235 - val_acc: 0.9375\n",
            "Epoch 11/150\n",
            "108/108 [==============================] - 829s 8s/step - loss: 1.0596 - acc: 0.6844 - val_loss: 0.4526 - val_acc: 0.8468\n",
            "Epoch 12/150\n",
            "108/108 [==============================] - 830s 8s/step - loss: 0.9975 - acc: 0.6822 - val_loss: 2.0466 - val_acc: 0.0601\n",
            "Epoch 13/150\n",
            "108/108 [==============================] - 826s 8s/step - loss: 0.9832 - acc: 0.7084 - val_loss: 1.1444 - val_acc: 0.0635\n",
            "Epoch 14/150\n",
            "108/108 [==============================] - 830s 8s/step - loss: 0.9765 - acc: 0.6883 - val_loss: 0.4295 - val_acc: 0.9389\n",
            "Epoch 15/150\n",
            "108/108 [==============================] - 829s 8s/step - loss: 0.9457 - acc: 0.7230 - val_loss: 0.6401 - val_acc: 0.6142\n",
            "Epoch 16/150\n",
            "108/108 [==============================] - 819s 8s/step - loss: 0.9652 - acc: 0.7154 - val_loss: 0.2257 - val_acc: 0.9399\n",
            "Epoch 17/150\n",
            "108/108 [==============================] - 819s 8s/step - loss: 0.9376 - acc: 0.7206 - val_loss: 0.6425 - val_acc: 0.6362\n",
            "Epoch 18/150\n",
            "108/108 [==============================] - 821s 8s/step - loss: 0.9505 - acc: 0.7088 - val_loss: 0.2455 - val_acc: 0.9399\n",
            "Epoch 19/150\n",
            "108/108 [==============================] - 819s 8s/step - loss: 0.9501 - acc: 0.7307 - val_loss: 2.4158 - val_acc: 0.0611\n",
            "Epoch 20/150\n",
            "108/108 [==============================] - 823s 8s/step - loss: 0.8890 - acc: 0.7328 - val_loss: 1.9704 - val_acc: 0.0601\n",
            "Epoch 21/150\n",
            "108/108 [==============================] - 831s 8s/step - loss: 0.8770 - acc: 0.7266 - val_loss: 2.3525 - val_acc: 0.0629\n",
            "Epoch 22/150\n",
            "107/108 [============================>.] - ETA: 1s - loss: 0.8799 - acc: 0.7309"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-bde2029e9487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                              \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcallback_list_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                             class_weight=class_weight)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                  \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                                  str(generator_output))\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fqfxpdKs9i3F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T1fexfQZLyjj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model (save_dir+save_file+'_loss_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XUDWjWDNL7wY",
        "colab_type": "code",
        "outputId": "967a9103-9e8a-4bc4-8394-d5daec06add8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "verify_datagen = ImageDataGenerator(rescale=1./255)\n",
        "verify_generator = verify_datagen.flow_from_directory(src_valid,target_size=(h_size,w_size),shuffle=False)\n",
        "\n",
        "verify_len = len(verify_generator.filenames)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "val_length = len(valid_generator.filenames)\n",
        "val_pred = model.predict_generator(verify_generator, verify_len, verbose=1 )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1742 images belonging to 2 classes.\n",
            "1742/1742 [==============================] - 786s 451ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JSc_wQ_XEX-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-BKRHePnOWRD",
        "colab_type": "code",
        "outputId": "ca0256d7-678a-486c-9447-41227deeff0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate_generator(valid_generator,1742//32, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54/54 [==============================] - 832s 15s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26562471933829696, 0.9397244547952467]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "_gvu8imtMqth",
        "colab_type": "code",
        "outputId": "9493cbc5-4eec-4f48-b9c3-2c643c7e6260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "cell_type": "code",
      "source": [
        "from  sklearn.metrics import roc_auc_score, matthews_corrcoef, accuracy_score\n",
        "acc = accuracy_score(valid_generator.classes,val_pred)\n",
        "auc  = acc = roc_auc_score(valid_generator.classes, val_pred)\n",
        "mcorr  = acc = matthews_corrcoef(valid_generator.classes, val_pred)\n",
        "print (acc, auc, mcorr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ba8db5662e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m  \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mauc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmcorr\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcorr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [105, 55186]"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rlnbImEdpZ-2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Start Testing"
      ]
    },
    {
      "metadata": {
        "id": "yzHsDsFdScDw",
        "colab_type": "code",
        "outputId": "ed281c49-429d-472f-f505-e023b334296a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=src_test,\n",
        "    target_size=(h_size,w_size),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20337 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rAh2FUSzf01B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4e3d3458-7e53-444c-bfc6-f13b4439c58e"
      },
      "cell_type": "code",
      "source": [
        "filenames = test_generator.filenames\n",
        "\n",
        "print (filenames[:5])\n",
        "nb_samples = len(filenames)\n",
        "filenames.sort()\n",
        "\n",
        "print (filenames[:5])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['test/signal_img_10000.png', 'test/signal_img_10001.png', 'test/signal_img_10002.png', 'test/signal_img_10003.png', 'test/signal_img_10004.png']\n",
            "['test/signal_img_10000.png', 'test/signal_img_10001.png', 'test/signal_img_10002.png', 'test/signal_img_10003.png', 'test/signal_img_10004.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aUM2lIjuf7MW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "606edccc-509a-42a5-be31-6f15ca82b00c"
      },
      "cell_type": "code",
      "source": [
        "len(os.listdir(src_test+'test/'))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "uDTpi1_2pVBH",
        "colab_type": "code",
        "outputId": "09209c1e-8e5a-48c0-b974-f6340bb881e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28336
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "\n",
        "print (filenames[:5])\n",
        "nb_samples = len(filenames)\n",
        "filenames.sort()\n",
        "\n",
        "print (filenames[:5])\n",
        "\n",
        "print (nb_samples)\n",
        "\n",
        "pred_list = []\n",
        "\n",
        "for i in range(nb_samples//batch+1): \n",
        "  im_list = []\n",
        "  \n",
        "  for f in filenames[i*batch:i*batch + batch]:\n",
        "\n",
        "    im = load_img(src_test+f)\n",
        "    im = im.resize((288,144))\n",
        "    img = img_to_array(im)\n",
        "    img = img/255.\n",
        "    im_list.append(img)\n",
        "    test_batch = np.stack(im_list, axis=0)\n",
        "    #print (test_batch.shape)\n",
        "    \n",
        "  pred = model.predict(test_batch)\n",
        "  print (pred.shape, pred[:5])\n",
        "\n",
        "  pred_list.append(pred)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['test/signal_img_10000.png', 'test/signal_img_10001.png', 'test/signal_img_10002.png', 'test/signal_img_10003.png', 'test/signal_img_10004.png']\n",
            "['test/signal_img_10000.png', 'test/signal_img_10001.png', 'test/signal_img_10002.png', 'test/signal_img_10003.png', 'test/signal_img_10004.png']\n",
            "20337\n",
            "(64, 1) [[0.05141986]\n",
            " [0.0516821 ]\n",
            " [0.05368991]\n",
            " [0.05257785]\n",
            " [0.05367244]]\n",
            "(64, 1) [[0.04815684]\n",
            " [0.05197988]\n",
            " [0.04844897]\n",
            " [0.05022674]\n",
            " [0.04849987]]\n",
            "(64, 1) [[0.05411623]\n",
            " [0.05315318]\n",
            " [0.05306452]\n",
            " [0.04935703]\n",
            " [0.048597  ]]\n",
            "(64, 1) [[0.03790148]\n",
            " [0.04418252]\n",
            " [0.04766922]\n",
            " [0.04562597]\n",
            " [0.04820319]]\n",
            "(64, 1) [[0.04713051]\n",
            " [0.05176834]\n",
            " [0.0502628 ]\n",
            " [0.05156368]\n",
            " [0.04635252]]\n",
            "(64, 1) [[0.04846216]\n",
            " [0.05090415]\n",
            " [0.05190379]\n",
            " [0.05062268]\n",
            " [0.05013379]]\n",
            "(64, 1) [[0.04932099]\n",
            " [0.04985908]\n",
            " [0.04969727]\n",
            " [0.04882577]\n",
            " [0.04859016]]\n",
            "(64, 1) [[0.04439341]\n",
            " [0.05172596]\n",
            " [0.05104259]\n",
            " [0.05172045]\n",
            " [0.04261347]]\n",
            "(64, 1) [[0.04842095]\n",
            " [0.04933437]\n",
            " [0.05189273]\n",
            " [0.03990575]\n",
            " [0.04055218]]\n",
            "(64, 1) [[0.05128786]\n",
            " [0.0509739 ]\n",
            " [0.04425204]\n",
            " [0.04002629]\n",
            " [0.04435902]]\n",
            "(64, 1) [[0.04756805]\n",
            " [0.04010375]\n",
            " [0.03984962]\n",
            " [0.04527192]\n",
            " [0.05116673]]\n",
            "(64, 1) [[0.05037041]\n",
            " [0.05136638]\n",
            " [0.05200937]\n",
            " [0.04841594]\n",
            " [0.0508471 ]]\n",
            "(64, 1) [[0.05061433]\n",
            " [0.05282386]\n",
            " [0.04734705]\n",
            " [0.04695202]\n",
            " [0.04576549]]\n",
            "(64, 1) [[0.05087392]\n",
            " [0.04950595]\n",
            " [0.04763988]\n",
            " [0.04806215]\n",
            " [0.04689379]]\n",
            "(64, 1) [[0.04950782]\n",
            " [0.05023557]\n",
            " [0.05217603]\n",
            " [0.04916497]\n",
            " [0.04875421]]\n",
            "(64, 1) [[0.04883723]\n",
            " [0.04984275]\n",
            " [0.0498817 ]\n",
            " [0.04984422]\n",
            " [0.04996993]]\n",
            "(64, 1) [[0.04782353]\n",
            " [0.04860154]\n",
            " [0.04805766]\n",
            " [0.04773806]\n",
            " [0.04955516]]\n",
            "(64, 1) [[0.04712474]\n",
            " [0.04185624]\n",
            " [0.04807602]\n",
            " [0.04958678]\n",
            " [0.05197887]]\n",
            "(64, 1) [[0.04553654]\n",
            " [0.0480521 ]\n",
            " [0.05018822]\n",
            " [0.05013831]\n",
            " [0.0511672 ]]\n",
            "(64, 1) [[0.05373705]\n",
            " [0.04859919]\n",
            " [0.04277841]\n",
            " [0.04626178]\n",
            " [0.05180587]]\n",
            "(64, 1) [[0.05104095]\n",
            " [0.0515264 ]\n",
            " [0.05177794]\n",
            " [0.05153888]\n",
            " [0.05184506]]\n",
            "(64, 1) [[0.04612423]\n",
            " [0.04895731]\n",
            " [0.04146303]\n",
            " [0.04114532]\n",
            " [0.0462484 ]]\n",
            "(64, 1) [[0.04348961]\n",
            " [0.04879027]\n",
            " [0.04954068]\n",
            " [0.051227  ]\n",
            " [0.04958349]]\n",
            "(64, 1) [[0.04914168]\n",
            " [0.04884656]\n",
            " [0.05036373]\n",
            " [0.04098426]\n",
            " [0.03958951]]\n",
            "(64, 1) [[0.03888606]\n",
            " [0.04579624]\n",
            " [0.04379452]\n",
            " [0.04159101]\n",
            " [0.04588031]]\n",
            "(64, 1) [[0.04972849]\n",
            " [0.04955172]\n",
            " [0.04823632]\n",
            " [0.04813874]\n",
            " [0.03875984]]\n",
            "(64, 1) [[0.05229756]\n",
            " [0.05125938]\n",
            " [0.05079702]\n",
            " [0.03989379]\n",
            " [0.03939968]]\n",
            "(64, 1) [[0.05012108]\n",
            " [0.0500141 ]\n",
            " [0.0547204 ]\n",
            " [0.05408387]\n",
            " [0.05499395]]\n",
            "(64, 1) [[0.04337336]\n",
            " [0.05004221]\n",
            " [0.05046595]\n",
            " [0.05151227]\n",
            " [0.05176187]]\n",
            "(64, 1) [[0.0509661 ]\n",
            " [0.05016852]\n",
            " [0.05119928]\n",
            " [0.04951187]\n",
            " [0.04654717]]\n",
            "(64, 1) [[0.05019702]\n",
            " [0.04972434]\n",
            " [0.05083615]\n",
            " [0.05187497]\n",
            " [0.05275799]]\n",
            "(64, 1) [[0.05004228]\n",
            " [0.05110509]\n",
            " [0.05188379]\n",
            " [0.05182054]\n",
            " [0.0408908 ]]\n",
            "(64, 1) [[0.04430356]\n",
            " [0.0429628 ]\n",
            " [0.04777561]\n",
            " [0.05150343]\n",
            " [0.05235469]]\n",
            "(64, 1) [[0.04091354]\n",
            " [0.04445804]\n",
            " [0.04287576]\n",
            " [0.04330993]\n",
            " [0.0437452 ]]\n",
            "(64, 1) [[0.04840901]\n",
            " [0.05293843]\n",
            " [0.05269792]\n",
            " [0.0538136 ]\n",
            " [0.05082533]]\n",
            "(64, 1) [[0.04241036]\n",
            " [0.04248167]\n",
            " [0.04461421]\n",
            " [0.04153681]\n",
            " [0.04159163]]\n",
            "(64, 1) [[0.03959871]\n",
            " [0.04799921]\n",
            " [0.04343683]\n",
            " [0.04155307]\n",
            " [0.04329328]]\n",
            "(64, 1) [[0.05015605]\n",
            " [0.04549188]\n",
            " [0.04301126]\n",
            " [0.04584994]\n",
            " [0.043132  ]]\n",
            "(64, 1) [[0.04613563]\n",
            " [0.04643786]\n",
            " [0.04774124]\n",
            " [0.05023756]\n",
            " [0.04850896]]\n",
            "(64, 1) [[0.04677778]\n",
            " [0.04956452]\n",
            " [0.05035406]\n",
            " [0.05030926]\n",
            " [0.05050675]]\n",
            "(64, 1) [[0.05362246]\n",
            " [0.05101494]\n",
            " [0.05010273]\n",
            " [0.05356846]\n",
            " [0.05257666]]\n",
            "(64, 1) [[0.03666684]\n",
            " [0.03777665]\n",
            " [0.04549694]\n",
            " [0.04502463]\n",
            " [0.04274773]]\n",
            "(64, 1) [[0.04481877]\n",
            " [0.0490747 ]\n",
            " [0.04683787]\n",
            " [0.04485167]\n",
            " [0.04854103]]\n",
            "(64, 1) [[0.0500972 ]\n",
            " [0.04055613]\n",
            " [0.04403314]\n",
            " [0.04406818]\n",
            " [0.05022971]]\n",
            "(64, 1) [[0.04810954]\n",
            " [0.04843993]\n",
            " [0.0474207 ]\n",
            " [0.04666397]\n",
            " [0.04463638]]\n",
            "(64, 1) [[0.04744552]\n",
            " [0.04942554]\n",
            " [0.04111576]\n",
            " [0.03934329]\n",
            " [0.04521145]]\n",
            "(64, 1) [[0.05278422]\n",
            " [0.05125841]\n",
            " [0.04845107]\n",
            " [0.05041412]\n",
            " [0.04808795]]\n",
            "(64, 1) [[0.03921897]\n",
            " [0.03889063]\n",
            " [0.04363855]\n",
            " [0.05090642]\n",
            " [0.0502185 ]]\n",
            "(64, 1) [[0.0407697 ]\n",
            " [0.04424188]\n",
            " [0.05088713]\n",
            " [0.05040711]\n",
            " [0.05041524]]\n",
            "(64, 1) [[0.051433  ]\n",
            " [0.04984823]\n",
            " [0.05139358]\n",
            " [0.05213264]\n",
            " [0.05025568]]\n",
            "(64, 1) [[0.05033104]\n",
            " [0.04826007]\n",
            " [0.05041028]\n",
            " [0.04922587]\n",
            " [0.04998353]]\n",
            "(64, 1) [[0.04655209]\n",
            " [0.04798243]\n",
            " [0.05508158]\n",
            " [0.05296703]\n",
            " [0.05346273]]\n",
            "(64, 1) [[0.04603878]\n",
            " [0.04940981]\n",
            " [0.05209529]\n",
            " [0.0515324 ]\n",
            " [0.04516666]]\n",
            "(64, 1) [[0.04701719]\n",
            " [0.04819644]\n",
            " [0.04780207]\n",
            " [0.04326315]\n",
            " [0.0418634 ]]\n",
            "(64, 1) [[0.04884982]\n",
            " [0.05126691]\n",
            " [0.05523865]\n",
            " [0.05485433]\n",
            " [0.05431865]]\n",
            "(64, 1) [[0.04810588]\n",
            " [0.0460635 ]\n",
            " [0.0431911 ]\n",
            " [0.04719796]\n",
            " [0.04216734]]\n",
            "(64, 1) [[0.04908396]\n",
            " [0.04778585]\n",
            " [0.0485243 ]\n",
            " [0.04645679]\n",
            " [0.04362829]]\n",
            "(64, 1) [[0.05154769]\n",
            " [0.05092848]\n",
            " [0.04414152]\n",
            " [0.03908752]\n",
            " [0.04680191]]\n",
            "(64, 1) [[0.0496528 ]\n",
            " [0.04695825]\n",
            " [0.04270457]\n",
            " [0.04734771]\n",
            " [0.04787977]]\n",
            "(64, 1) [[0.04182658]\n",
            " [0.0431687 ]\n",
            " [0.04422433]\n",
            " [0.05184427]\n",
            " [0.04892338]]\n",
            "(64, 1) [[0.04258813]\n",
            " [0.04627135]\n",
            " [0.05335078]\n",
            " [0.05248692]\n",
            " [0.05307576]]\n",
            "(64, 1) [[0.04473007]\n",
            " [0.05082287]\n",
            " [0.04769184]\n",
            " [0.04897761]\n",
            " [0.04846863]]\n",
            "(64, 1) [[0.05131277]\n",
            " [0.05173099]\n",
            " [0.05240342]\n",
            " [0.051465  ]\n",
            " [0.04896744]]\n",
            "(64, 1) [[0.04983173]\n",
            " [0.04820499]\n",
            " [0.04971901]\n",
            " [0.04428948]\n",
            " [0.04926867]]\n",
            "(64, 1) [[0.04918466]\n",
            " [0.05135795]\n",
            " [0.0477798 ]\n",
            " [0.04976046]\n",
            " [0.04888551]]\n",
            "(64, 1) [[0.05194217]\n",
            " [0.04699691]\n",
            " [0.04724364]\n",
            " [0.0461861 ]\n",
            " [0.04329104]]\n",
            "(64, 1) [[0.04897548]\n",
            " [0.04877156]\n",
            " [0.04057895]\n",
            " [0.03864111]\n",
            " [0.04524652]]\n",
            "(64, 1) [[0.05257533]\n",
            " [0.04935289]\n",
            " [0.05163975]\n",
            " [0.05188707]\n",
            " [0.05115264]]\n",
            "(64, 1) [[0.0461338 ]\n",
            " [0.04297861]\n",
            " [0.05115484]\n",
            " [0.04915877]\n",
            " [0.0462978 ]]\n",
            "(64, 1) [[0.04812473]\n",
            " [0.04788004]\n",
            " [0.04446121]\n",
            " [0.04183657]\n",
            " [0.04580899]]\n",
            "(64, 1) [[0.04995567]\n",
            " [0.04780691]\n",
            " [0.04718484]\n",
            " [0.04700276]\n",
            " [0.04917041]]\n",
            "(64, 1) [[0.03747069]\n",
            " [0.04285968]\n",
            " [0.04562226]\n",
            " [0.05208724]\n",
            " [0.05186952]]\n",
            "(64, 1) [[0.04844483]\n",
            " [0.04857144]\n",
            " [0.04505113]\n",
            " [0.04538955]\n",
            " [0.04743648]]\n",
            "(64, 1) [[0.04557669]\n",
            " [0.05158782]\n",
            " [0.0512206 ]\n",
            " [0.05210659]\n",
            " [0.0432297 ]]\n",
            "(64, 1) [[0.05063128]\n",
            " [0.05187973]\n",
            " [0.05230442]\n",
            " [0.05019796]\n",
            " [0.04992611]]\n",
            "(64, 1) [[0.05122294]\n",
            " [0.05125289]\n",
            " [0.04841644]\n",
            " [0.05146797]\n",
            " [0.05085146]]\n",
            "(64, 1) [[0.04563193]\n",
            " [0.05020886]\n",
            " [0.04739861]\n",
            " [0.04844017]\n",
            " [0.05382162]]\n",
            "(64, 1) [[0.05082433]\n",
            " [0.04816645]\n",
            " [0.05030369]\n",
            " [0.05169751]\n",
            " [0.05210484]]\n",
            "(64, 1) [[0.04136975]\n",
            " [0.04648418]\n",
            " [0.04392168]\n",
            " [0.04225162]\n",
            " [0.04578675]]\n",
            "(64, 1) [[0.052025  ]\n",
            " [0.04968872]\n",
            " [0.04960975]\n",
            " [0.04888448]\n",
            " [0.05021988]]\n",
            "(64, 1) [[0.05154657]\n",
            " [0.04612989]\n",
            " [0.05008296]\n",
            " [0.04748654]\n",
            " [0.04818236]]\n",
            "(64, 1) [[0.04898779]\n",
            " [0.04925616]\n",
            " [0.03786153]\n",
            " [0.03875673]\n",
            " [0.04499549]]\n",
            "(64, 1) [[0.0466773 ]\n",
            " [0.05095541]\n",
            " [0.04635554]\n",
            " [0.04913687]\n",
            " [0.04773677]]\n",
            "(64, 1) [[0.05054447]\n",
            " [0.05127636]\n",
            " [0.05195448]\n",
            " [0.05150025]\n",
            " [0.04832983]]\n",
            "(64, 1) [[0.05043048]\n",
            " [0.05194471]\n",
            " [0.0508826 ]\n",
            " [0.04987767]\n",
            " [0.04945358]]\n",
            "(64, 1) [[0.04989682]\n",
            " [0.0403773 ]\n",
            " [0.04179054]\n",
            " [0.04457876]\n",
            " [0.04723793]]\n",
            "(64, 1) [[0.04176675]\n",
            " [0.04002529]\n",
            " [0.04467026]\n",
            " [0.04720382]\n",
            " [0.05043766]]\n",
            "(64, 1) [[0.04423586]\n",
            " [0.04749993]\n",
            " [0.04372664]\n",
            " [0.04299668]\n",
            " [0.04608161]]\n",
            "(64, 1) [[0.05332284]\n",
            " [0.05217321]\n",
            " [0.05173059]\n",
            " [0.05098023]\n",
            " [0.05308853]]\n",
            "(64, 1) [[0.04883499]\n",
            " [0.04805437]\n",
            " [0.04894039]\n",
            " [0.04921957]\n",
            " [0.05055149]]\n",
            "(64, 1) [[0.05236869]\n",
            " [0.05309913]\n",
            " [0.04440269]\n",
            " [0.0433469 ]\n",
            " [0.0460516 ]]\n",
            "(64, 1) [[0.04877402]\n",
            " [0.04923409]\n",
            " [0.04732433]\n",
            " [0.04883775]\n",
            " [0.05156382]]\n",
            "(64, 1) [[0.05066308]\n",
            " [0.04985492]\n",
            " [0.05034148]\n",
            " [0.0433934 ]\n",
            " [0.04328994]]\n",
            "(64, 1) [[0.0517558 ]\n",
            " [0.05134927]\n",
            " [0.05118588]\n",
            " [0.05219559]\n",
            " [0.05197131]]\n",
            "(64, 1) [[0.05229182]\n",
            " [0.04208849]\n",
            " [0.04042017]\n",
            " [0.04606895]\n",
            " [0.04469516]]\n",
            "(64, 1) [[0.04227618]\n",
            " [0.04442926]\n",
            " [0.04582895]\n",
            " [0.04951279]\n",
            " [0.05089593]]\n",
            "(64, 1) [[0.05089328]\n",
            " [0.05320039]\n",
            " [0.04019718]\n",
            " [0.03900123]\n",
            " [0.04454803]]\n",
            "(64, 1) [[0.04882408]\n",
            " [0.05155073]\n",
            " [0.0522774 ]\n",
            " [0.05199724]\n",
            " [0.05099963]]\n",
            "(64, 1) [[0.04858796]\n",
            " [0.04890037]\n",
            " [0.04866516]\n",
            " [0.0528598 ]\n",
            " [0.05260349]]\n",
            "(64, 1) [[0.05201982]\n",
            " [0.05243408]\n",
            " [0.04972994]\n",
            " [0.049916  ]\n",
            " [0.04967061]]\n",
            "(64, 1) [[0.04812459]\n",
            " [0.05174612]\n",
            " [0.05258789]\n",
            " [0.05332664]\n",
            " [0.04159403]]\n",
            "(64, 1) [[0.04957426]\n",
            " [0.04908125]\n",
            " [0.04849387]\n",
            " [0.05160771]\n",
            " [0.05179106]]\n",
            "(64, 1) [[0.04868907]\n",
            " [0.04976936]\n",
            " [0.05131203]\n",
            " [0.05008572]\n",
            " [0.05139256]]\n",
            "(64, 1) [[0.04908147]\n",
            " [0.04586435]\n",
            " [0.04422585]\n",
            " [0.04759444]\n",
            " [0.0503466 ]]\n",
            "(64, 1) [[0.0408621 ]\n",
            " [0.03924833]\n",
            " [0.04494184]\n",
            " [0.05026936]\n",
            " [0.05016299]]\n",
            "(64, 1) [[0.05040839]\n",
            " [0.05149821]\n",
            " [0.04107703]\n",
            " [0.04353838]\n",
            " [0.04436886]]\n",
            "(64, 1) [[0.05007795]\n",
            " [0.04843608]\n",
            " [0.04769832]\n",
            " [0.04695588]\n",
            " [0.04100849]]\n",
            "(64, 1) [[0.04923199]\n",
            " [0.04915378]\n",
            " [0.05088948]\n",
            " [0.04722356]\n",
            " [0.04735788]]\n",
            "(64, 1) [[0.14311536]\n",
            " [0.13714235]\n",
            " [0.05220703]\n",
            " [0.05213499]\n",
            " [0.0515033 ]]\n",
            "(64, 1) [[0.04641178]\n",
            " [0.04091633]\n",
            " [0.04433785]\n",
            " [0.0456013 ]\n",
            " [0.04951502]]\n",
            "(64, 1) [[0.04354393]\n",
            " [0.04340938]\n",
            " [0.04555946]\n",
            " [0.05156788]\n",
            " [0.05013045]]\n",
            "(64, 1) [[0.044985  ]\n",
            " [0.04682516]\n",
            " [0.04866432]\n",
            " [0.04777396]\n",
            " [0.05099237]]\n",
            "(64, 1) [[0.04915301]\n",
            " [0.05120903]\n",
            " [0.05034638]\n",
            " [0.05116387]\n",
            " [0.05245639]]\n",
            "(64, 1) [[0.04651357]\n",
            " [0.04561583]\n",
            " [0.04733938]\n",
            " [0.04978214]\n",
            " [0.04963788]]\n",
            "(64, 1) [[0.04355748]\n",
            " [0.04446375]\n",
            " [0.05498993]\n",
            " [0.05440745]\n",
            " [0.05532517]]\n",
            "(64, 1) [[0.04733458]\n",
            " [0.04764545]\n",
            " [0.04922336]\n",
            " [0.05063758]\n",
            " [0.05114843]]\n",
            "(64, 1) [[0.05056633]\n",
            " [0.04801144]\n",
            " [0.04925425]\n",
            " [0.04976851]\n",
            " [0.04957727]]\n",
            "(64, 1) [[0.04201879]\n",
            " [0.04452443]\n",
            " [0.04227136]\n",
            " [0.0392444 ]\n",
            " [0.04470216]]\n",
            "(64, 1) [[0.05004781]\n",
            " [0.05006025]\n",
            " [0.04730703]\n",
            " [0.05104036]\n",
            " [0.04304989]]\n",
            "(64, 1) [[0.04957158]\n",
            " [0.0507065 ]\n",
            " [0.05193576]\n",
            " [0.03841685]\n",
            " [0.03856242]]\n",
            "(64, 1) [[0.04473203]\n",
            " [0.04566182]\n",
            " [0.04019105]\n",
            " [0.03832305]\n",
            " [0.04403537]]\n",
            "(64, 1) [[0.04586803]\n",
            " [0.04095646]\n",
            " [0.04198912]\n",
            " [0.04492645]\n",
            " [0.05064999]]\n",
            "(64, 1) [[0.04654047]\n",
            " [0.04586105]\n",
            " [0.04675668]\n",
            " [0.05147313]\n",
            " [0.05182559]]\n",
            "(64, 1) [[0.04924484]\n",
            " [0.04951803]\n",
            " [0.04816624]\n",
            " [0.04518725]\n",
            " [0.04839452]]\n",
            "(64, 1) [[0.05045346]\n",
            " [0.04357803]\n",
            " [0.04137046]\n",
            " [0.04487056]\n",
            " [0.04057308]]\n",
            "(64, 1) [[0.04947297]\n",
            " [0.04775834]\n",
            " [0.04803371]\n",
            " [0.04391061]\n",
            " [0.03935653]]\n",
            "(64, 1) [[0.03737913]\n",
            " [0.04437229]\n",
            " [0.04392675]\n",
            " [0.04261921]\n",
            " [0.04596002]]\n",
            "(64, 1) [[0.05157968]\n",
            " [0.05038233]\n",
            " [0.04507075]\n",
            " [0.04870849]\n",
            " [0.04125739]]\n",
            "(64, 1) [[0.04418525]\n",
            " [0.04303798]\n",
            " [0.04587366]\n",
            " [0.04792375]\n",
            " [0.04914824]]\n",
            "(64, 1) [[0.04583135]\n",
            " [0.05055458]\n",
            " [0.04841179]\n",
            " [0.04665233]\n",
            " [0.04814593]]\n",
            "(64, 1) [[0.05379101]\n",
            " [0.05141479]\n",
            " [0.0502306 ]\n",
            " [0.05037166]\n",
            " [0.04367841]]\n",
            "(64, 1) [[0.04963585]\n",
            " [0.0505189 ]\n",
            " [0.05149502]\n",
            " [0.04051562]\n",
            " [0.03824208]]\n",
            "(64, 1) [[0.05403122]\n",
            " [0.05309047]\n",
            " [0.05115598]\n",
            " [0.05231078]\n",
            " [0.05275678]]\n",
            "(64, 1) [[0.04849118]\n",
            " [0.04532599]\n",
            " [0.04690917]\n",
            " [0.04780731]\n",
            " [0.0470081 ]]\n",
            "(64, 1) [[0.05171616]\n",
            " [0.05050519]\n",
            " [0.05114663]\n",
            " [0.05192736]\n",
            " [0.05223417]]\n",
            "(64, 1) [[0.05114066]\n",
            " [0.05156574]\n",
            " [0.04968295]\n",
            " [0.04688046]\n",
            " [0.04704516]]\n",
            "(64, 1) [[0.051882  ]\n",
            " [0.04379838]\n",
            " [0.04284587]\n",
            " [0.04513612]\n",
            " [0.0520656 ]]\n",
            "(64, 1) [[0.04630534]\n",
            " [0.0462139 ]\n",
            " [0.04851402]\n",
            " [0.04902428]\n",
            " [0.04868422]]\n",
            "(64, 1) [[0.04603014]\n",
            " [0.0474339 ]\n",
            " [0.04475499]\n",
            " [0.04600093]\n",
            " [0.0497946 ]]\n",
            "(64, 1) [[0.04594762]\n",
            " [0.05047782]\n",
            " [0.05129463]\n",
            " [0.05149602]\n",
            " [0.04340798]]\n",
            "(64, 1) [[0.05242262]\n",
            " [0.05165015]\n",
            " [0.05223865]\n",
            " [0.05022253]\n",
            " [0.05178015]]\n",
            "(64, 1) [[0.05013528]\n",
            " [0.05130747]\n",
            " [0.05146246]\n",
            " [0.050141  ]\n",
            " [0.05209813]]\n",
            "(64, 1) [[0.0519075 ]\n",
            " [0.04252155]\n",
            " [0.04302074]\n",
            " [0.04500613]\n",
            " [0.05001754]]\n",
            "(64, 1) [[0.05098909]\n",
            " [0.0515434 ]\n",
            " [0.05248658]\n",
            " [0.0483482 ]\n",
            " [0.04647035]]\n",
            "(64, 1) [[0.0501483 ]\n",
            " [0.0512827 ]\n",
            " [0.05282914]\n",
            " [0.05302747]\n",
            " [0.05332883]]\n",
            "(64, 1) [[0.04498522]\n",
            " [0.05351588]\n",
            " [0.05302226]\n",
            " [0.05316565]\n",
            " [0.05271129]]\n",
            "(64, 1) [[0.0405244 ]\n",
            " [0.040283  ]\n",
            " [0.04349401]\n",
            " [0.0499469 ]\n",
            " [0.04974222]]\n",
            "(64, 1) [[0.0427779 ]\n",
            " [0.04699387]\n",
            " [0.04806032]\n",
            " [0.04950726]\n",
            " [0.0495206 ]]\n",
            "(64, 1) [[0.04975755]\n",
            " [0.04343795]\n",
            " [0.04232176]\n",
            " [0.04597253]\n",
            " [0.05071627]]\n",
            "(64, 1) [[0.04927821]\n",
            " [0.04954483]\n",
            " [0.05010234]\n",
            " [0.04392864]\n",
            " [0.0414987 ]]\n",
            "(64, 1) [[0.03714687]\n",
            " [0.04463483]\n",
            " [0.05050859]\n",
            " [0.0516867 ]\n",
            " [0.0527163 ]]\n",
            "(64, 1) [[0.05163704]\n",
            " [0.04858939]\n",
            " [0.05017092]\n",
            " [0.04990303]\n",
            " [0.04370649]]\n",
            "(64, 1) [[0.04169722]\n",
            " [0.04312655]\n",
            " [0.04528615]\n",
            " [0.04231835]\n",
            " [0.04350474]]\n",
            "(64, 1) [[0.0421842 ]\n",
            " [0.04572242]\n",
            " [0.04906249]\n",
            " [0.05140961]\n",
            " [0.05131294]]\n",
            "(64, 1) [[0.05009634]\n",
            " [0.04876046]\n",
            " [0.04748213]\n",
            " [0.04734887]\n",
            " [0.05119792]]\n",
            "(64, 1) [[0.04807732]\n",
            " [0.0485375 ]\n",
            " [0.04861736]\n",
            " [0.04383551]\n",
            " [0.04151766]]\n",
            "(64, 1) [[0.04831783]\n",
            " [0.04980746]\n",
            " [0.04921939]\n",
            " [0.0485745 ]\n",
            " [0.04961032]]\n",
            "(64, 1) [[0.0504019 ]\n",
            " [0.05046776]\n",
            " [0.0447152 ]\n",
            " [0.0479545 ]\n",
            " [0.04179541]]\n",
            "(64, 1) [[0.05044911]\n",
            " [0.04995031]\n",
            " [0.05186745]\n",
            " [0.04470488]\n",
            " [0.04071487]]\n",
            "(64, 1) [[0.05022189]\n",
            " [0.05240289]\n",
            " [0.05162665]\n",
            " [0.05176391]\n",
            " [0.05234466]]\n",
            "(64, 1) [[0.0536153 ]\n",
            " [0.05072823]\n",
            " [0.04985721]\n",
            " [0.05256619]\n",
            " [0.05019917]]\n",
            "(64, 1) [[0.04259264]\n",
            " [0.04204622]\n",
            " [0.04747318]\n",
            " [0.04421194]\n",
            " [0.04348158]]\n",
            "(64, 1) [[0.04874467]\n",
            " [0.04826972]\n",
            " [0.04219033]\n",
            " [0.04063284]\n",
            " [0.04399003]]\n",
            "(64, 1) [[0.04998203]\n",
            " [0.04762783]\n",
            " [0.04786827]\n",
            " [0.05056822]\n",
            " [0.04971746]]\n",
            "(64, 1) [[0.04118677]\n",
            " [0.04104664]\n",
            " [0.045396  ]\n",
            " [0.05421031]\n",
            " [0.05378707]]\n",
            "(64, 1) [[0.05023561]\n",
            " [0.05265993]\n",
            " [0.04769431]\n",
            " [0.04903346]\n",
            " [0.04807739]]\n",
            "(64, 1) [[0.0504495 ]\n",
            " [0.053153  ]\n",
            " [0.04907421]\n",
            " [0.05123876]\n",
            " [0.05016716]]\n",
            "(64, 1) [[0.0459433 ]\n",
            " [0.04500826]\n",
            " [0.04607673]\n",
            " [0.05170571]\n",
            " [0.0528435 ]]\n",
            "(64, 1) [[0.04696779]\n",
            " [0.04901003]\n",
            " [0.04674057]\n",
            " [0.04417081]\n",
            " [0.04611987]]\n",
            "(64, 1) [[0.05323689]\n",
            " [0.04230113]\n",
            " [0.04213062]\n",
            " [0.04314778]\n",
            " [0.04834035]]\n",
            "(64, 1) [[0.05164732]\n",
            " [0.04974326]\n",
            " [0.05041477]\n",
            " [0.03857151]\n",
            " [0.03975257]]\n",
            "(64, 1) [[0.04541272]\n",
            " [0.04952024]\n",
            " [0.04741314]\n",
            " [0.04808437]\n",
            " [0.05082155]]\n",
            "(64, 1) [[0.04594121]\n",
            " [0.05053247]\n",
            " [0.05142587]\n",
            " [0.05139584]\n",
            " [0.05247193]]\n",
            "(64, 1) [[0.0435718 ]\n",
            " [0.04396068]\n",
            " [0.04536007]\n",
            " [0.04765943]\n",
            " [0.04566884]]\n",
            "(64, 1) [[0.0448674 ]\n",
            " [0.0486272 ]\n",
            " [0.04281932]\n",
            " [0.04221655]\n",
            " [0.04556566]]\n",
            "(64, 1) [[0.04795123]\n",
            " [0.04729207]\n",
            " [0.04636041]\n",
            " [0.04700681]\n",
            " [0.05372439]]\n",
            "(64, 1) [[0.04770841]\n",
            " [0.04688675]\n",
            " [0.04985232]\n",
            " [0.04818005]\n",
            " [0.05024325]]\n",
            "(64, 1) [[0.05185522]\n",
            " [0.05247355]\n",
            " [0.04026519]\n",
            " [0.03994636]\n",
            " [0.04541108]]\n",
            "(64, 1) [[0.04449034]\n",
            " [0.04471371]\n",
            " [0.04189648]\n",
            " [0.04614351]\n",
            " [0.04911559]]\n",
            "(64, 1) [[0.05006092]\n",
            " [0.04930224]\n",
            " [0.05034899]\n",
            " [0.04526828]\n",
            " [0.04967483]]\n",
            "(64, 1) [[0.05379342]\n",
            " [0.05296279]\n",
            " [0.05038671]\n",
            " [0.04589245]\n",
            " [0.0491572 ]]\n",
            "(64, 1) [[0.04723078]\n",
            " [0.05156191]\n",
            " [0.05041568]\n",
            " [0.05072702]\n",
            " [0.05011419]]\n",
            "(64, 1) [[0.05321805]\n",
            " [0.04719288]\n",
            " [0.0474573 ]\n",
            " [0.04917655]\n",
            " [0.04688611]]\n",
            "(64, 1) [[0.03797674]\n",
            " [0.04513567]\n",
            " [0.04461884]\n",
            " [0.04365264]\n",
            " [0.04623099]]\n",
            "(64, 1) [[0.04636477]\n",
            " [0.04221553]\n",
            " [0.04163353]\n",
            " [0.0444653 ]\n",
            " [0.05255816]]\n",
            "(64, 1) [[0.0450176 ]\n",
            " [0.04643236]\n",
            " [0.04738447]\n",
            " [0.03895844]\n",
            " [0.04057   ]]\n",
            "(64, 1) [[0.04545344]\n",
            " [0.04565226]\n",
            " [0.04351363]\n",
            " [0.0417231 ]\n",
            " [0.04545192]]\n",
            "(64, 1) [[0.04683724]\n",
            " [0.05085311]\n",
            " [0.0510818 ]\n",
            " [0.05161622]\n",
            " [0.05033138]]\n",
            "(64, 1) [[0.04990063]\n",
            " [0.04763027]\n",
            " [0.04755969]\n",
            " [0.05061195]\n",
            " [0.05252156]]\n",
            "(64, 1) [[0.04711879]\n",
            " [0.04786647]\n",
            " [0.04934399]\n",
            " [0.04937628]\n",
            " [0.04858854]]\n",
            "(64, 1) [[0.05010591]\n",
            " [0.05001802]\n",
            " [0.049694  ]\n",
            " [0.04928587]\n",
            " [0.0513956 ]]\n",
            "(64, 1) [[0.05440172]\n",
            " [0.0533036 ]\n",
            " [0.05326653]\n",
            " [0.04976219]\n",
            " [0.04988078]]\n",
            "(64, 1) [[0.04609571]\n",
            " [0.05058182]\n",
            " [0.04039816]\n",
            " [0.04006233]\n",
            " [0.04527454]]\n",
            "(64, 1) [[0.04643335]\n",
            " [0.04556715]\n",
            " [0.0440214 ]\n",
            " [0.0467972 ]\n",
            " [0.05183462]]\n",
            "(64, 1) [[0.0521986 ]\n",
            " [0.05153479]\n",
            " [0.05210022]\n",
            " [0.04301006]\n",
            " [0.0425609 ]]\n",
            "(64, 1) [[0.05379338]\n",
            " [0.05271043]\n",
            " [0.04662872]\n",
            " [0.04663442]\n",
            " [0.04782061]]\n",
            "(64, 1) [[0.04979105]\n",
            " [0.04736087]\n",
            " [0.04544965]\n",
            " [0.04736957]\n",
            " [0.05041741]]\n",
            "(64, 1) [[0.04846581]\n",
            " [0.04528734]\n",
            " [0.04718275]\n",
            " [0.04823248]\n",
            " [0.04923181]]\n",
            "(64, 1) [[0.0512614 ]\n",
            " [0.05173184]\n",
            " [0.04340826]\n",
            " [0.04653797]\n",
            " [0.04735145]]\n",
            "(64, 1) [[0.0493319 ]\n",
            " [0.04978337]\n",
            " [0.04768122]\n",
            " [0.0470231 ]\n",
            " [0.04084235]]\n",
            "(64, 1) [[0.04315491]\n",
            " [0.04183351]\n",
            " [0.04560609]\n",
            " [0.05180934]\n",
            " [0.05190054]]\n",
            "(64, 1) [[0.04930716]\n",
            " [0.05026694]\n",
            " [0.0489306 ]\n",
            " [0.05063633]\n",
            " [0.05190304]]\n",
            "(64, 1) [[0.04965716]\n",
            " [0.04964591]\n",
            " [0.05068053]\n",
            " [0.05174689]\n",
            " [0.05055177]]\n",
            "(64, 1) [[0.04383965]\n",
            " [0.04317415]\n",
            " [0.04652914]\n",
            " [0.04684248]\n",
            " [0.0446404 ]]\n",
            "(64, 1) [[0.05053553]\n",
            " [0.04986271]\n",
            " [0.0441105 ]\n",
            " [0.04690599]\n",
            " [0.04850337]]\n",
            "(64, 1) [[0.04422818]\n",
            " [0.04062735]\n",
            " [0.04309853]\n",
            " [0.04657706]\n",
            " [0.04957591]]\n",
            "(64, 1) [[0.04311112]\n",
            " [0.03859144]\n",
            " [0.04484497]\n",
            " [0.04268843]\n",
            " [0.04280252]]\n",
            "(64, 1) [[0.04832289]\n",
            " [0.0508875 ]\n",
            " [0.04412972]\n",
            " [0.04286501]\n",
            " [0.04477711]]\n",
            "(64, 1) [[0.04527918]\n",
            " [0.04946643]\n",
            " [0.04936032]\n",
            " [0.04962156]\n",
            " [0.04316438]]\n",
            "(64, 1) [[0.04045394]\n",
            " [0.03937058]\n",
            " [0.0450616 ]\n",
            " [0.05150288]\n",
            " [0.04846987]]\n",
            "(64, 1) [[0.05081468]\n",
            " [0.05189842]\n",
            " [0.05030758]\n",
            " [0.04810715]\n",
            " [0.05105332]]\n",
            "(64, 1) [[0.04552101]\n",
            " [0.04409055]\n",
            " [0.04308983]\n",
            " [0.0457642 ]\n",
            " [0.0505977 ]]\n",
            "(64, 1) [[0.05534031]\n",
            " [0.05360243]\n",
            " [0.05432147]\n",
            " [0.05212143]\n",
            " [0.05242058]]\n",
            "(64, 1) [[0.04196729]\n",
            " [0.0449902 ]\n",
            " [0.05421165]\n",
            " [0.05311259]\n",
            " [0.05407006]]\n",
            "(64, 1) [[0.05139285]\n",
            " [0.04699079]\n",
            " [0.04476325]\n",
            " [0.04831319]\n",
            " [0.04737169]]\n",
            "(64, 1) [[0.04329501]\n",
            " [0.04332498]\n",
            " [0.04513141]\n",
            " [0.0513904 ]\n",
            " [0.049737  ]]\n",
            "(64, 1) [[0.04035515]\n",
            " [0.04527985]\n",
            " [0.04998247]\n",
            " [0.04778328]\n",
            " [0.04824485]]\n",
            "(64, 1) [[0.04966085]\n",
            " [0.04855426]\n",
            " [0.04800139]\n",
            " [0.04811711]\n",
            " [0.04266957]]\n",
            "(64, 1) [[0.04507792]\n",
            " [0.04268329]\n",
            " [0.04508381]\n",
            " [0.04754521]\n",
            " [0.04388655]]\n",
            "(64, 1) [[0.05306328]\n",
            " [0.05313172]\n",
            " [0.04805504]\n",
            " [0.0483498 ]\n",
            " [0.05060592]]\n",
            "(64, 1) [[0.04798669]\n",
            " [0.04964077]\n",
            " [0.0490799 ]\n",
            " [0.04921594]\n",
            " [0.05342026]]\n",
            "(64, 1) [[0.05002425]\n",
            " [0.04989961]\n",
            " [0.05113349]\n",
            " [0.05009828]\n",
            " [0.0511581 ]]\n",
            "(64, 1) [[0.0504634 ]\n",
            " [0.05226533]\n",
            " [0.04309072]\n",
            " [0.03709102]\n",
            " [0.0503512 ]]\n",
            "(64, 1) [[0.04613062]\n",
            " [0.05089115]\n",
            " [0.04700386]\n",
            " [0.04829756]\n",
            " [0.05358423]]\n",
            "(64, 1) [[0.04250655]\n",
            " [0.04187651]\n",
            " [0.04518287]\n",
            " [0.0480439 ]\n",
            " [0.04838326]]\n",
            "(64, 1) [[0.05168353]\n",
            " [0.05215101]\n",
            " [0.05307608]\n",
            " [0.05237305]\n",
            " [0.05348967]]\n",
            "(64, 1) [[0.04886441]\n",
            " [0.04061143]\n",
            " [0.04069662]\n",
            " [0.04443182]\n",
            " [0.04831616]]\n",
            "(64, 1) [[0.05184228]\n",
            " [0.05294095]\n",
            " [0.05322441]\n",
            " [0.04881408]\n",
            " [0.04912029]]\n",
            "(64, 1) [[0.05246982]\n",
            " [0.05350543]\n",
            " [0.04787906]\n",
            " [0.04950602]\n",
            " [0.05003002]]\n",
            "(64, 1) [[0.04617777]\n",
            " [0.04898786]\n",
            " [0.04823728]\n",
            " [0.0474194 ]\n",
            " [0.05198643]]\n",
            "(64, 1) [[0.04434141]\n",
            " [0.04236755]\n",
            " [0.04441699]\n",
            " [0.0503722 ]\n",
            " [0.04898389]]\n",
            "(64, 1) [[0.05250854]\n",
            " [0.05370196]\n",
            " [0.04842733]\n",
            " [0.04584077]\n",
            " [0.04881887]]\n",
            "(64, 1) [[0.04591863]\n",
            " [0.0438266 ]\n",
            " [0.04277919]\n",
            " [0.04560413]\n",
            " [0.04347923]]\n",
            "(64, 1) [[0.05229583]\n",
            " [0.04915514]\n",
            " [0.05090538]\n",
            " [0.0495657 ]\n",
            " [0.04894981]]\n",
            "(64, 1) [[0.0517388 ]\n",
            " [0.05183167]\n",
            " [0.03841896]\n",
            " [0.03780631]\n",
            " [0.04432298]]\n",
            "(64, 1) [[0.05212463]\n",
            " [0.05403315]\n",
            " [0.05370167]\n",
            " [0.05311064]\n",
            " [0.05069063]]\n",
            "(64, 1) [[0.04530271]\n",
            " [0.04285778]\n",
            " [0.04513636]\n",
            " [0.05110539]\n",
            " [0.05058549]]\n",
            "(64, 1) [[0.04304145]\n",
            " [0.04663151]\n",
            " [0.04422358]\n",
            " [0.04762653]\n",
            " [0.04895824]]\n",
            "(64, 1) [[0.05338224]\n",
            " [0.04579017]\n",
            " [0.04628918]\n",
            " [0.04800966]\n",
            " [0.04347598]]\n",
            "(64, 1) [[0.05061991]\n",
            " [0.05106538]\n",
            " [0.05222258]\n",
            " [0.04244547]\n",
            " [0.04033057]]\n",
            "(64, 1) [[0.04829862]\n",
            " [0.04789705]\n",
            " [0.04967227]\n",
            " [0.04496607]\n",
            " [0.04830607]]\n",
            "(64, 1) [[0.04588949]\n",
            " [0.05240633]\n",
            " [0.05141476]\n",
            " [0.05040409]\n",
            " [0.04522507]]\n",
            "(64, 1) [[0.04185655]\n",
            " [0.04004961]\n",
            " [0.04437184]\n",
            " [0.04852036]\n",
            " [0.04652858]]\n",
            "(64, 1) [[0.0512623 ]\n",
            " [0.05115969]\n",
            " [0.04675013]\n",
            " [0.04525204]\n",
            " [0.04692267]]\n",
            "(64, 1) [[0.05156623]\n",
            " [0.05167242]\n",
            " [0.0521317 ]\n",
            " [0.05032164]\n",
            " [0.04885796]]\n",
            "(64, 1) [[0.04357418]\n",
            " [0.04120846]\n",
            " [0.04613517]\n",
            " [0.13979584]\n",
            " [0.12688869]]\n",
            "(64, 1) [[0.03855136]\n",
            " [0.04503293]\n",
            " [0.04403622]\n",
            " [0.04006145]\n",
            " [0.04583002]]\n",
            "(64, 1) [[0.05057043]\n",
            " [0.04694938]\n",
            " [0.04601526]\n",
            " [0.04790577]\n",
            " [0.05141953]]\n",
            "(64, 1) [[0.0493301 ]\n",
            " [0.05290329]\n",
            " [0.05260132]\n",
            " [0.04576297]\n",
            " [0.04362614]]\n",
            "(64, 1) [[0.04545255]\n",
            " [0.04991781]\n",
            " [0.04987181]\n",
            " [0.04940973]\n",
            " [0.05088286]]\n",
            "(64, 1) [[0.05050167]\n",
            " [0.04157385]\n",
            " [0.04313441]\n",
            " [0.04535255]\n",
            " [0.05108311]]\n",
            "(64, 1) [[0.03880452]\n",
            " [0.03711464]\n",
            " [0.04308414]\n",
            " [0.05328048]\n",
            " [0.0498166 ]]\n",
            "(64, 1) [[0.05229988]\n",
            " [0.05174788]\n",
            " [0.04995455]\n",
            " [0.04756888]\n",
            " [0.04940691]]\n",
            "(64, 1) [[0.05211033]\n",
            " [0.04641473]\n",
            " [0.042741  ]\n",
            " [0.04732073]\n",
            " [0.04658457]]\n",
            "(64, 1) [[0.05108268]\n",
            " [0.05007818]\n",
            " [0.04984602]\n",
            " [0.04217422]\n",
            " [0.04080416]]\n",
            "(64, 1) [[0.04118359]\n",
            " [0.04590562]\n",
            " [0.05043704]\n",
            " [0.04534579]\n",
            " [0.04923108]]\n",
            "(64, 1) [[0.0443636 ]\n",
            " [0.04999921]\n",
            " [0.05109747]\n",
            " [0.05130555]\n",
            " [0.0522123 ]]\n",
            "(64, 1) [[0.04751416]\n",
            " [0.04394805]\n",
            " [0.04903071]\n",
            " [0.05022083]\n",
            " [0.04893394]]\n",
            "(64, 1) [[0.04133806]\n",
            " [0.04644681]\n",
            " [0.04898404]\n",
            " [0.04804837]\n",
            " [0.04764735]]\n",
            "(64, 1) [[0.04938899]\n",
            " [0.04689457]\n",
            " [0.04698564]\n",
            " [0.04913342]\n",
            " [0.04986307]]\n",
            "(64, 1) [[0.04725222]\n",
            " [0.04647995]\n",
            " [0.04917485]\n",
            " [0.0502941 ]\n",
            " [0.04867334]]\n",
            "(64, 1) [[0.05101346]\n",
            " [0.05008513]\n",
            " [0.04521181]\n",
            " [0.04370014]\n",
            " [0.04559103]]\n",
            "(64, 1) [[0.04793474]\n",
            " [0.05341082]\n",
            " [0.05455123]\n",
            " [0.05314505]\n",
            " [0.04698115]]\n",
            "(64, 1) [[0.05353133]\n",
            " [0.05138875]\n",
            " [0.05178598]\n",
            " [0.04351659]\n",
            " [0.04183251]]\n",
            "(64, 1) [[0.05172882]\n",
            " [0.05217382]\n",
            " [0.04648317]\n",
            " [0.04334598]\n",
            " [0.04584585]]\n",
            "(64, 1) [[0.04660534]\n",
            " [0.04925837]\n",
            " [0.04868753]\n",
            " [0.04838549]\n",
            " [0.04235158]]\n",
            "(64, 1) [[0.04451501]\n",
            " [0.04245555]\n",
            " [0.04544578]\n",
            " [0.05088007]\n",
            " [0.04576017]]\n",
            "(64, 1) [[0.05198737]\n",
            " [0.05226909]\n",
            " [0.04937055]\n",
            " [0.04784042]\n",
            " [0.05200953]]\n",
            "(64, 1) [[0.04902707]\n",
            " [0.05346109]\n",
            " [0.05259759]\n",
            " [0.05197178]\n",
            " [0.04370719]]\n",
            "(64, 1) [[0.04931683]\n",
            " [0.04869122]\n",
            " [0.04822158]\n",
            " [0.04668276]\n",
            " [0.04411324]]\n",
            "(64, 1) [[0.04445684]\n",
            " [0.04818163]\n",
            " [0.05097993]\n",
            " [0.05297318]\n",
            " [0.05364823]]\n",
            "(64, 1) [[0.05085122]\n",
            " [0.04186079]\n",
            " [0.04108101]\n",
            " [0.04302371]\n",
            " [0.0406571 ]]\n",
            "(64, 1) [[0.04196746]\n",
            " [0.04010056]\n",
            " [0.04585556]\n",
            " [0.04929633]\n",
            " [0.04879716]]\n",
            "(64, 1) [[0.04580073]\n",
            " [0.04800742]\n",
            " [0.04477221]\n",
            " [0.04431793]\n",
            " [0.04592994]]\n",
            "(64, 1) [[0.05452278]\n",
            " [0.05066304]\n",
            " [0.05107486]\n",
            " [0.04884356]\n",
            " [0.04251454]]\n",
            "(64, 1) [[0.04908071]\n",
            " [0.04843788]\n",
            " [0.04853606]\n",
            " [0.04384435]\n",
            " [0.04143563]]\n",
            "(64, 1) [[0.13759603]\n",
            " [0.12354083]\n",
            " [0.05126395]\n",
            " [0.05235541]\n",
            " [0.05238704]]\n",
            "(64, 1) [[0.0509292 ]\n",
            " [0.04360109]\n",
            " [0.04640864]\n",
            " [0.04741123]\n",
            " [0.05029864]]\n",
            "(64, 1) [[0.05229543]\n",
            " [0.05181849]\n",
            " [0.0526658 ]\n",
            " [0.05064917]\n",
            " [0.05067896]]\n",
            "(64, 1) [[0.05438944]\n",
            " [0.053542  ]\n",
            " [0.05251954]\n",
            " [0.05207644]\n",
            " [0.05173313]]\n",
            "(64, 1) [[0.0521418 ]\n",
            " [0.05103634]\n",
            " [0.04896416]\n",
            " [0.04945238]\n",
            " [0.05018031]]\n",
            "(64, 1) [[0.04214926]\n",
            " [0.04354399]\n",
            " [0.04675981]\n",
            " [0.04410767]\n",
            " [0.04338231]]\n",
            "(64, 1) [[0.05228988]\n",
            " [0.05285195]\n",
            " [0.04569117]\n",
            " [0.0435051 ]\n",
            " [0.04701154]]\n",
            "(64, 1) [[0.04852422]\n",
            " [0.04103814]\n",
            " [0.03814203]\n",
            " [0.04145059]\n",
            " [0.04967301]]\n",
            "(64, 1) [[0.05151559]\n",
            " [0.04796489]\n",
            " [0.04873585]\n",
            " [0.04877692]\n",
            " [0.04753964]]\n",
            "(64, 1) [[0.05030328]\n",
            " [0.05192069]\n",
            " [0.05102825]\n",
            " [0.05179406]\n",
            " [0.05212042]]\n",
            "(64, 1) [[0.04684702]\n",
            " [0.04488376]\n",
            " [0.04303439]\n",
            " [0.04748705]\n",
            " [0.04088161]]\n",
            "(64, 1) [[0.05245935]\n",
            " [0.05182698]\n",
            " [0.05147787]\n",
            " [0.04813124]\n",
            " [0.04568154]]\n",
            "(64, 1) [[0.04950137]\n",
            " [0.05073382]\n",
            " [0.04850146]\n",
            " [0.04763893]\n",
            " [0.04893093]]\n",
            "(64, 1) [[0.05101956]\n",
            " [0.05074249]\n",
            " [0.04988136]\n",
            " [0.05233489]\n",
            " [0.04287875]]\n",
            "(64, 1) [[0.04753394]\n",
            " [0.05041059]\n",
            " [0.05234738]\n",
            " [0.04502715]\n",
            " [0.0418608 ]]\n",
            "(64, 1) [[0.0421619 ]\n",
            " [0.04379212]\n",
            " [0.04212099]\n",
            " [0.04180117]\n",
            " [0.04579864]]\n",
            "(64, 1) [[0.04485556]\n",
            " [0.05003244]\n",
            " [0.04991402]\n",
            " [0.0499698 ]\n",
            " [0.04946382]]\n",
            "(64, 1) [[0.0499166 ]\n",
            " [0.05109804]\n",
            " [0.05137518]\n",
            " [0.04460767]\n",
            " [0.04474438]]\n",
            "(64, 1) [[0.04666702]\n",
            " [0.04835029]\n",
            " [0.04759222]\n",
            " [0.04578289]\n",
            " [0.04941681]]\n",
            "(64, 1) [[0.05220424]\n",
            " [0.04427785]\n",
            " [0.04223926]\n",
            " [0.04616989]\n",
            " [0.05017674]]\n",
            "(64, 1) [[0.04976478]\n",
            " [0.04864528]\n",
            " [0.04912928]\n",
            " [0.04881182]\n",
            " [0.04676573]]\n",
            "(64, 1) [[0.04807586]\n",
            " [0.05060316]\n",
            " [0.04878001]\n",
            " [0.04954715]\n",
            " [0.04928372]]\n",
            "(64, 1) [[0.04905529]\n",
            " [0.04849959]\n",
            " [0.04806308]\n",
            " [0.05167144]\n",
            " [0.04267826]]\n",
            "(64, 1) [[0.0450099 ]\n",
            " [0.04469134]\n",
            " [0.04616388]\n",
            " [0.05104176]\n",
            " [0.04853793]]\n",
            "(64, 1) [[0.05212189]\n",
            " [0.05274872]\n",
            " [0.05289203]\n",
            " [0.05250222]\n",
            " [0.05241654]]\n",
            "(64, 1) [[0.0450708 ]\n",
            " [0.0503987 ]\n",
            " [0.05068286]\n",
            " [0.05200945]\n",
            " [0.05089452]]\n",
            "(64, 1) [[0.0473746 ]\n",
            " [0.04864405]\n",
            " [0.04835981]\n",
            " [0.05046117]\n",
            " [0.05073189]]\n",
            "(64, 1) [[0.04888642]\n",
            " [0.04824345]\n",
            " [0.05077845]\n",
            " [0.0504813 ]\n",
            " [0.05135856]]\n",
            "(64, 1) [[0.0495728 ]\n",
            " [0.05113271]\n",
            " [0.05046299]\n",
            " [0.05019824]\n",
            " [0.05128506]]\n",
            "(64, 1) [[0.04720181]\n",
            " [0.04620395]\n",
            " [0.04744966]\n",
            " [0.05160179]\n",
            " [0.05123238]]\n",
            "(64, 1) [[0.04854584]\n",
            " [0.04906681]\n",
            " [0.05197355]\n",
            " [0.05174088]\n",
            " [0.05191661]]\n",
            "(64, 1) [[0.05119175]\n",
            " [0.04540575]\n",
            " [0.04407127]\n",
            " [0.04896423]\n",
            " [0.04806897]]\n",
            "(64, 1) [[0.04917976]\n",
            " [0.04937142]\n",
            " [0.0514527 ]\n",
            " [0.05110044]\n",
            " [0.05117134]]\n",
            "(64, 1) [[0.04526894]\n",
            " [0.04882426]\n",
            " [0.05174411]\n",
            " [0.05183759]\n",
            " [0.05259638]]\n",
            "(64, 1) [[0.04505466]\n",
            " [0.04620694]\n",
            " [0.04330732]\n",
            " [0.04685627]\n",
            " [0.0448513 ]]\n",
            "(64, 1) [[0.0426356 ]\n",
            " [0.04258012]\n",
            " [0.04679715]\n",
            " [0.05244851]\n",
            " [0.05225538]]\n",
            "(64, 1) [[0.05247539]\n",
            " [0.05228142]\n",
            " [0.04812966]\n",
            " [0.05031769]\n",
            " [0.05141302]]\n",
            "(64, 1) [[0.04477441]\n",
            " [0.05504732]\n",
            " [0.05529621]\n",
            " [0.05433051]\n",
            " [0.04225261]]\n",
            "(64, 1) [[0.04257759]\n",
            " [0.0419286 ]\n",
            " [0.04565397]\n",
            " [0.05047014]\n",
            " [0.04697875]]\n",
            "(64, 1) [[0.04771177]\n",
            " [0.05059538]\n",
            " [0.04981948]\n",
            " [0.04650554]\n",
            " [0.0484234 ]]\n",
            "(64, 1) [[0.05042192]\n",
            " [0.04261712]\n",
            " [0.04001014]\n",
            " [0.04567627]\n",
            " [0.05385202]]\n",
            "(49, 1) [[0.03926662]\n",
            " [0.03577029]\n",
            " [0.04279087]\n",
            " [0.04427427]\n",
            " [0.04180296]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XDilREP3mRai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ead9354-cccf-4313-d88f-03b790e32878"
      },
      "cell_type": "code",
      "source": [
        "with open (src+'pred_list.pkl','wb') as handle:\n",
        "  pickle.dump(pred_list, handle)\n",
        "\n",
        "print ('pred_list.pkl saved')  "
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred_list.pkl saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ogRfgL5pEFz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4863cdfa-cf76-45ba-aa35-833041e58393"
      },
      "cell_type": "code",
      "source": [
        "final_pred = np.vstack(pred_list)\n",
        "print (final_pred.shape)\n",
        "\n",
        "final_pred = np.squeeze(final_pred)\n",
        "print (final_pred.shape)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20337, 1)\n",
            "(20337,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bhVIQuRl9IqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ec57d6d-84c8-4e80-ae61-70d75c26da28"
      },
      "cell_type": "code",
      "source": [
        "with open (src+'final_pred.pkl','wb') as handle:\n",
        "  pickle.dump(final_pred, handle)\n",
        "\n",
        "print ('final_pred.pkl saved')  "
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_pred.pkl saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rat6jzUIpVPd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "with open(src+'test_pred.pkl','wb') as handle:\n",
        "  pickle.dump(pred, handle)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6LfCekYfpVT1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8533e620-2667-4a0b-e4b6-661fb42e3c1c"
      },
      "cell_type": "code",
      "source": [
        "with open(src+'filenames.pkl','wb') as handle:\n",
        "  pickle.dump(filenames, handle)\n",
        "print ('finenames saved')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finenames saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VWb6RgT2pVXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_TSbc3lpVbc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MX5AKjsUQJAJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xeqxPeizxphX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYgB_Nkixpp8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3VFgdDHxptV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WSaVqQNZxp01",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjBjSNvltVoi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_df =pd.read_csv(src+'metadata_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVcQJOJQtlOp",
        "colab_type": "code",
        "outputId": "9e65937d-6b1a-49e9-ffdc-c222ebbaa9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>signal_id</th>\n",
              "      <th>id_measurement</th>\n",
              "      <th>phase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8712</td>\n",
              "      <td>2904</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8713</td>\n",
              "      <td>2904</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8714</td>\n",
              "      <td>2904</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8715</td>\n",
              "      <td>2905</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8716</td>\n",
              "      <td>2905</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   signal_id  id_measurement  phase\n",
              "0       8712            2904      0\n",
              "1       8713            2904      1\n",
              "2       8714            2904      2\n",
              "3       8715            2905      0\n",
              "4       8716            2905      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "MQHu_RJVto-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "ebfc8e9b-7f36-4126-c7c4-fad06709b92a"
      },
      "cell_type": "code",
      "source": [
        "os.listdir(src)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test.parquet',\n",
              " 'sample_submission.csv',\n",
              " 'metadata_test.csv',\n",
              " 'metadata_train.csv',\n",
              " 'train.parquet',\n",
              " 'all.zip',\n",
              " 'vsb_power_line_eda.ipynb',\n",
              " 'train_test_data',\n",
              " 'vsb_power_line_DenseNet121_1st__acc.h5',\n",
              " 'vsb_power_line_DenseNet121_1st__loss.h5',\n",
              " 'vsb_power_line_DenseNet121_1st__acc_2.h5',\n",
              " 'vsb_power_line_DenseNet121_1st__loss_2.h5',\n",
              " 'train_test_data_2',\n",
              " 'id_label.csv',\n",
              " 'new_train.csv',\n",
              " 'pred_list.pkl',\n",
              " 'final_pred.pkl',\n",
              " 'filenames.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "Hl_Vghts9-RY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "8fa1b7d0-7c75-4523-f200-5a0f8f4ab899"
      },
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv(src+'sample_submission.csv')\n",
        "sample.head()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>signal_id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8712</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8713</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8714</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8715</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   signal_id  target\n",
              "0       8712       0\n",
              "1       8713       0\n",
              "2       8714       0\n",
              "3       8715       0\n",
              "4       8716       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "metadata": {
        "id": "G56gtr1C-IZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "7ccc86a5-6708-40ee-a5d8-c14fe51f1674"
      },
      "cell_type": "code",
      "source": [
        "test_dict = {'test_id': filenames,\n",
        "            'test_pred': final_pred}\n",
        "\n",
        "test_df = pd.DataFrame(test_dict)\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>test_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test/signal_img_10000.png</td>\n",
              "      <td>0.051420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test/signal_img_10001.png</td>\n",
              "      <td>0.051682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test/signal_img_10002.png</td>\n",
              "      <td>0.053690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test/signal_img_10003.png</td>\n",
              "      <td>0.052578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test/signal_img_10004.png</td>\n",
              "      <td>0.053672</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     test_id  test_pred\n",
              "0  test/signal_img_10000.png   0.051420\n",
              "1  test/signal_img_10001.png   0.051682\n",
              "2  test/signal_img_10002.png   0.053690\n",
              "3  test/signal_img_10003.png   0.052578\n",
              "4  test/signal_img_10004.png   0.053672"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "metadata": {
        "id": "53yM2RNU_QJz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_id(f):\n",
        "  return int(f[16:-4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Lo3JcTg_arB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "fd99470d-33f4-407c-ea0f-ede02ff8865e"
      },
      "cell_type": "code",
      "source": [
        "test_df['test_id'] = test_df['test_id'].map(get_id)\n",
        "test_df=test_df.sort_values(by = ['test_id'])\n",
        "test_df = test_df.reset_index()\n",
        "test_df.head()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>test_id</th>\n",
              "      <th>test_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19049</td>\n",
              "      <td>8712</td>\n",
              "      <td>0.049872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19050</td>\n",
              "      <td>8713</td>\n",
              "      <td>0.049254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19051</td>\n",
              "      <td>8714</td>\n",
              "      <td>0.048784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19052</td>\n",
              "      <td>8715</td>\n",
              "      <td>0.048443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19053</td>\n",
              "      <td>8716</td>\n",
              "      <td>0.045041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  test_id  test_pred\n",
              "0  19049     8712   0.049872\n",
              "1  19050     8713   0.049254\n",
              "2  19051     8714   0.048784\n",
              "3  19052     8715   0.048443\n",
              "4  19053     8716   0.045041"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "metadata": {
        "id": "-dfv5qsbDZye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "9622550c-a2dc-4108-e381-d9ab0d734db1"
      },
      "cell_type": "code",
      "source": [
        "test_df['test_pred'] = ( test_df['test_pred'] >0.4)*1\n",
        "test_df.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>test_id</th>\n",
              "      <th>test_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19049</td>\n",
              "      <td>8712</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19050</td>\n",
              "      <td>8713</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19051</td>\n",
              "      <td>8714</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19052</td>\n",
              "      <td>8715</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19053</td>\n",
              "      <td>8716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  test_id  test_pred\n",
              "0  19049     8712          0\n",
              "1  19050     8713          0\n",
              "2  19051     8714          0\n",
              "3  19052     8715          0\n",
              "4  19053     8716          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {
        "id": "srgUcAJBANki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "52c2103b-d761-4cd6-c70f-14ec1a8aaaa3"
      },
      "cell_type": "code",
      "source": [
        "sample['target'] = test_df['test_pred']\n",
        "sample.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>signal_id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8712</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8713</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8714</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8715</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   signal_id  target\n",
              "0       8712       0\n",
              "1       8713       0\n",
              "2       8714       0\n",
              "3       8715       0\n",
              "4       8716       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "metadata": {
        "id": "F-feF_90BCfi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample.to_csv(src+'powerline_1st_0102_01.csv',index= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iMr6RWpFCZQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}